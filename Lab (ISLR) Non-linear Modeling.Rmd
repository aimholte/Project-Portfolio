#Lab: Non-linear Modeling

```{r}
library(ISLR)
attach(Wage)
```

```{r}
fit <- lm(wage ~ poly(age, 4), data = Wage)
coef(summary(fit))
```
```{r}
fit2 <- lm(wage ~ poly(age, 4, raw = T), data = Wage)
coef(summary(fit2))
fit2a <- lm(wage ~ age + I(age^2) + I(age^3) + I(age^4), data = Wage)
coef(fit2a)
```
```{r}
fit2b <- lm(wage ~ cbind(age, age^2, age^3, age^4), data = Wage)
```
Another technique that can be used instead of the others used above.
```{r}
agelims <- range(age)
age.grid <- seq(from=agelims [1],to=agelims [2])
preds <- predict (fit ,newdata =list(age=age.grid),se=TRUE)
se.bands <- cbind(preds$fit +2*preds$se.fit,preds$fit-2*preds$se.fit)
```
Plot the data and add the fit from the degree-4 polynomial.
```{r}
par(mfrow = c(1,2), mar = c(4.5,4.5,1,1), oma = c(0,0,4,0))
plot(age, wage, xlim = agelims, cex = .5, col = "darkgrey")
title("Degree-4 Polynomial", outer = T)
lines(age.grid, preds$fit, lwd = 2, col = "blue")
matlines(age.grid, se.bands, lwd = 1, col = "blue", lty = 3)
preds2 <- predict(fit2, newdata = list(age = age.grid),se = TRUE)
max(abs(preds$fit-preds2$fit))
```
Which degree polynomial is the best? Use ANOVA.
```{r}
fit.1 <- lm(wage ~ age, data = Wage)
fit.2 <- lm(wage ~ poly(age, 2), data = Wage)
fit.3 <- lm(wage ~ poly(age, 3), data = Wage)
fit.4 <- lm(wage ~ poly(age, 4), data = Wage)
fit.5 <- lm(wage ~ poly(age, 5), data = Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
```
Based off this output, either a cubic or quartic polynomial seems to reasonably fit the data. Anything higher or lower does not make sense in this case.
```{r}
coef(summary(fit.5))
```
This command gives us the same result as above, and leads us to the same conclusion as the ANOVA method (this is for orthogonal polynomials).
```{r}
fit.1 <- lm(wage ~ education + age, data = Wage)
fit.2 <- lm(wage ~ education + poly(age, 2), data = Wage)
fit.3 <- lm(wage ~ education + poly(age, 3), data = Wage)
anova(fit.1, fit.2, fit.3)
```
However, the ANOVA method works whether orthogonal polynomials are utilized or not. It also works when other terms are in the model as well. Another possible method is cross validation.

#Task: Predict whether an individual earns more than $250,000 per year.
```{r}
fit <- glm(I(wage > 250) ~ poly(age, 4), data = Wage, family = "binomial")
#The wrapper I() creates a binanry response. The expression wage > 250 yields a logical variable contrain TRUE's and FALSE's (GLM makes TRUE's 1 and FALSE's 0).
preds <- predict(fit, newdata = list(age = age.grid), se = T)
pfit <- exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit <- cbind(preds$fit + 2*preds$se.fit, preds$fit-2*preds$fit)
se.bands <- exp(se.bands.logit)/(1+exp(se.bands.logit))
```

```{r}
plot(age,I(wage>250),xlim=agelims,type="n",ylim=c(0,.2))
points(jitter(age), I((wage >250)/5),cex=.5,pch="|", col="darkgrey")
lines(age.grid ,pfit ,lwd=2, col="blue")
matlines (age.grid,se.bands,lwd=1,col="blue",lty=3)
```
```{r}
table(cut(age, 4))
fit <- lm(wage ~ cut(age, 4), data = Wage)
coef(summary(fit))
```
Step function estimate for wage.

#Splines
```{r}
library(splines)
fit <- lm(wage ~ bs(age, knots = c(25, 40, 60)), data = Wage)
pred <- predict(fit, newdata = list(age = age.grid), se = T)
plot(age, wage, col = "gray")
lines(age.grid, pred$fit, lwd = 2)
lines(age.grid, pred$fit + 2*pred$se, lty = "dashed")
lines(age.grid, pred$fit - 2*pred$se, lty = "dashed")
```

Prespecified knots at ages 25, 40, and 60. This will use six basis functions in this case.
```{r}
dim(bs(age, knots = c(25, 40, 60)))
dim(bs(age, df = 6))
attr(bs(age, df = 6), "knots")
```
R choosse knot at 33.75, 42, and 51, which correspond to the 25th, 50th, and 75th percentiles of age.
```{r}
fit2 <- lm(wage ~ ns(age, df = 4), data = Wage)
pred2 <- predict(fit2, newdata = list(age = age.grid), se = T)
plot(age, wage, col = "gray")
lines(age.grid, pred$fit, lwd = 2)
lines(age.grid, pred$fit + 2*pred$se, lty = "dashed")
lines(age.grid, pred$fit - 2*pred$se, lty = "dashed")
lines(age.grid, pred$fit, col = "red", lwd = 2)
```

```{r}
plot(age, wage, xlim = agelims, cex = .5, col = "darkgrey")
title("Smoothing Spline")
fit <- smooth.spline(age, wage, df = 16)
fit2 <- smooth.spline(age, wage, cv = TRUE)
fit2$df
lines(fit, col = "red", lwd = 2)
lines(fit2, col = "blue", lwd = 2)
legend("topright", legend = c("16 DF", "6.8 DF"), col = c("red", "blue"),
       lty = 1, lwd = 2, cex = .8)
```
```{r}
plot(age, wage, xlim = agelims, cex = .5, col = "darkgrey")
title("Local Regression")
fit <- loess(wage ~ age, span = .2, data = Wage)
fit2 <- loess(wage ~ age, span = .5, data = Wage)
lines(age.grid, predict(fit, data.frame(age = age.grid)), col = "red", lwd = 2)
lines(age.grid, predict(fit2, data.frame(age = age.grid)), col = "blue", lwd = 2)
legend("topright", legend = c("Span = 0.2", "Span = 0.5"),
       col = c("red", "blue"), lty = 1, lwd = 2, cex = .8)
```

#GAMs
```{r}
gam1 <- lm(wage ~ ns(year, 4) + ns(age, 5) + education, data = Wage)
```

```{r}
library(gam)
gam.m3 <- gam(wage ~ s(year, 4) + s(age, 5) + education, data = Wage)
par(mfrow = c(1, 3))
plot(gam.m3, se = TRUE, col = "blue")
plot.gam(gam1, se = TRUE, col = "red")
```
```{r}
gam.m1 <- gam(wage ~ s(age, 5) + education, data = Wage)
gam.m2 <- gam(wage ~ year + s(age, 5) + education, data = Wage)
anova(gam.m1, gam.m2, gam.m3, test = "F")
summary(gam.m3)
preds <- predict(gam.m2, newdata = Wage)
```
```{r}
library(akima)
gam.lo <- gam(wage ~ s(year, df = 4) + lo(age, span = 0.7) + education, data = Wage)
plot.gam(gam.lo, se = TRUE, col = "green")
gam.lo.i <- gam(wage ~ lo(year, age, span = 0.5) + education, data = Wage)
plot(gam.lo.i)
gam.lr <- gam(I(wage > 250) ~ year + s(age, df = 5) + education, family = "binomial", data = Wage)
par(mfrow = c(1, 3))
plot(gam.lr, se = T, col = "green")
```
```{r}
table(education, I(wage > 250))
```
```{r}
gam.lr.s <- gam(I(wage > 250) ~ year + s(age, df = 5) + education, family = "binomial", data = Wage, subset = (education != "1. < HS Grad"))
plot(gam.lr.s, se = T, col = "green")
```

